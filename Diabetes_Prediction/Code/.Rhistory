```
## Prediction
The trained model is used to predict the data for the testing data and for the training data(For checking accuracy purposes and for ROC curve)
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
By comparing the real values with the real data, we can see the how our machine learning algorithm performs.
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
## Data Loading
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
## Correlations
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```
## Visualization
Visualizations are used to grasp the structure of data and its relations,like how they vary and their
relationships with the otehr data.They are said to be EDA.
A matrix of scatterplots is produce for this dataset.
```{r}
pairs(data, col=data$Outcome)
```
### Glucose and Insulin
The glucose and the insulin are the major factors of the diabetes...which in turn have direct proportionality in the future during the diabetes.They are the major cause of the occurence.They are strong correlated on each other.
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```
### BMI ad DiabetesPedigreeFunction
The BMI and DiabetesPedigreeFunction is plotted here.
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```
### Age and Pregnancies
The males have 0 for the pregnancy attribute, which is why we find a lot of values plottinh zero in this grpah.
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```
## Preparing the data
The dataset is divided as two parts, training data and testing data, with a Splitratio of 0.75. It means that 2/3rds of the data is labelled by training set and the rest 1/3rd of data is the testing set.The division of the dataset is by means of a random order generated by the seed.
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```
## Logistic regression
The Logistic regression helps to classify the concern person will get diabetes or not.Since we are using the logistic regression we have to mention that, family = binomial.We are using all the attributes we have in the dataset.Let us take a look at the summary.
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```
## Prediction
The trained model is used to predict the data for the testing data and for the training data(For checking accuracy purposes and for ROC curve)
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
By comparing the real values with the real data, we can see the how our machine learning algorithm performs.
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
corrplot(correlations, method="color")
## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
## Data Loading
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
## Correlations
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```
## Visualization
Visualizations are used to grasp the structure of data and its relations,like how they vary and their
relationships with the otehr data.They are said to be EDA.
A matrix of scatterplots is produce for this dataset.
```{r}
pairs(data, col=data$Outcome)
```
### Glucose and Insulin
The glucose and the insulin are the major factors of the diabetes...which in turn have direct proportionality in the future during the diabetes.They are the major cause of the occurence.They are strong correlated on each other.
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```
### BMI ad DiabetesPedigreeFunction
The BMI and DiabetesPedigreeFunction is plotted here.
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```
### Age and Pregnancies
The males have 0 for the pregnancy attribute, which is why we find a lot of values plottinh zero in this grpah.
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```
## Preparing the data
The dataset is divided as two parts, training data and testing data, with a Splitratio of 0.75. It means that 2/3rds of the data is labelled by training set and the rest 1/3rd of data is the testing set.The division of the dataset is by means of a random order generated by the seed.
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```
## Logistic regression
The Logistic regression helps to classify the concern person will get diabetes or not.Since we are using the logistic regression we have to mention that, family = binomial.We are using all the attributes we have in the dataset.Let us take a look at the summary.
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```
## Prediction
The trained model is used to predict the data for the testing data and for the training data(For checking accuracy purposes and for ROC curve)
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
By comparing the real values with the real data, we can see the how our machine learning algorithm performs.
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
## Data Loading
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
## Correlations
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```
## Visualization
```{r}
pairs(data, col=data$Outcome)
```
### Glucose and Insulin
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```
### BMI ad DiabetesPedigreeFunction
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```
### Age and Pregnancies
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```
## Preparing the data
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```
## Logistic regression
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```
## Prediction
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
install.packages("predict-test")
## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
## Data Loading
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
## Correlations
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```
## Visualization
```{r}
pairs(data, col=data$Outcome)
```
### Glucose and Insulin
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```
### BMI ad DiabetesPedigreeFunction
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```
### Age and Pregnancies
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```
## Preparing the data
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```
## Logistic regression
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```
## Prediction
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
## Data Loading
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
## Correlations
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```
## Visualization
```{r}
pairs(data, col=data$Outcome)
```
### Glucose and Insulin
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```
### BMI ad DiabetesPedigreeFunction
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```
### Age and Pregnancies
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```
## Preparing the data
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```
## Logistic regression
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```
## Prediction
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
corrplot(correlations, method="color")
## Loading the required libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(ggvis)
library(corrplot)
library(caTools)
library(ROCR)
## Data Loading
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
## Correlations
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```
## Visualization
```{r}
pairs(data, col=data$Outcome)
```
### Glucose and Insulin
```{r}
data %>% ggvis(~Glucose,~Insulin,fill =~Outcome) %>% layer_points()
```
### BMI ad DiabetesPedigreeFunction
```{r}
data %>% ggvis(~BMI,~DiabetesPedigreeFunction,fill =~Outcome) %>% layer_points()
```
### Age and Pregnancies
```{r}
data %>% ggvis(~Age,~Pregnancies,fill =~Outcome) %>% layer_points()
```
## Preparing the data
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```
## Logistic regression
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```
## Prediction
```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')
```
## ROC Curve
```{r}
ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
```
## Comparison
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
if(predict_test[i] < 0.5)
predict_test_c[i] = 0
else
predict_test_c[i] = 1
i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```
data = read.csv("D:/diabetes.csv")
head(data)
summary(data)
str(data)
corrplot(correlations, method="color")
